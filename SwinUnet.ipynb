{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNbHbKGkDJlFElPHjkVXDsb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wnsports/SportsAnalyticsNotebook/blob/main/SwinUnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ApMkc0i1Dtg",
        "outputId": "ff2d62c1-9927-4df5-d272-e7313ad84aaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Swin-Unet'...\n",
            "remote: Enumerating objects: 98, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 98 (delta 24), reused 14 (delta 14), pack-reused 58 (from 1)\u001b[K\n",
            "Receiving objects: 100% (98/98), 42.76 KiB | 616.00 KiB/s, done.\n",
            "Resolving deltas: 100% (40/40), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/HuCaoFighting/Swin-Unet.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q ml-collections SimpleITK timm einops tensorboardX yacs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU4EWzMb8XaW",
        "outputId": "93732ef2-4444-4d84-9036-be8f62e25d3c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/Swin-Unet/train_custom.py\n",
        "\n",
        "import argparse\n",
        "import glob\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "from scipy.ndimage.interpolation import zoom\n",
        "from torch.utils.data import Dataset\n",
        "import random\n",
        "\n",
        "def random_rot_flip(image, label):\n",
        "    k = np.random.randint(0, 4)\n",
        "    image = np.rot90(image, k)\n",
        "    label = np.rot90(label, k)\n",
        "    axis = np.random.randint(0, 2)\n",
        "    image = np.flip(image, axis=axis).copy()\n",
        "    label = np.flip(label, axis=axis).copy()\n",
        "    return image, label\n",
        "\n",
        "\n",
        "def random_rotate(image, label):\n",
        "    angle = np.random.randint(-20, 20)\n",
        "    image = ndimage.rotate(image, angle, order=0, reshape=False)\n",
        "    label = ndimage.rotate(label, angle, order=0, reshape=False)\n",
        "    return image, label\n",
        "\n",
        "\n",
        "class RandomGenerator(object):\n",
        "    def __init__(self, output_size):\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, label = sample['image'], sample['label']\n",
        "\n",
        "        if random.random() > 0.5:\n",
        "            image, label = random_rot_flip(image, label)\n",
        "        elif random.random() > 0.5:\n",
        "            image, label = random_rotate(image, label)\n",
        "        x, y = image.shape[:2]\n",
        "        if x != self.output_size[0] or y != self.output_size[1]:\n",
        "            image = zoom(image, (self.output_size[0] / x, self.output_size[1] / y), order=3)  # why not 3?\n",
        "            label = zoom(label, (self.output_size[0] / x, self.output_size[1] / y), order=3)\n",
        "        image = torch.from_numpy(image.astype(np.float32)).unsqueeze(0)\n",
        "        label = torch.from_numpy(label.astype(np.float32)).unsqueeze(0)\n",
        "        sample = {'image': image, 'label': label}\n",
        "        return sample\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, base_dir, transform=None):\n",
        "        self.transform = transform  # using transform in torch!\n",
        "        self.data_dir = base_dir\n",
        "        self.input_files = sorted(glob.glob(self.data_dir + \"/inputs/*.jpg\"))\n",
        "        self.output_files = sorted(glob.glob(self.data_dir + \"/outputs/*.jpg\"))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_image = Image.open(self.input_files[idx])\n",
        "        output_image = Image.open(self.output_files[idx])\n",
        "\n",
        "        if self.transform:\n",
        "            input_image_tensor = self.transform(input_image)\n",
        "            output_image_tensor = self.transform(output_image)\n",
        "\n",
        "        sample = {'image': input_image_tensor, 'label': output_image_tensor}\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "# custom datasetを変更して、num_classes = 3にして、trainをmse_lossに変更？\n",
        "\n",
        "from networks.vision_transformer import SwinUnet\n",
        "from config import get_config\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tensorboardX import SummaryWriter\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "import os\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--root_path\", type=str, default=\"/content/datasets\")\n",
        "parser.add_argument('--num_classes', type=int,\n",
        "                    default=9, help='output channel of network')\n",
        "parser.add_argument('--output_dir', type=str, help='output dir')\n",
        "parser.add_argument('--max_iterations', type=int,\n",
        "                    default=30000, help='maximum epoch number to train')\n",
        "parser.add_argument('--max_epochs', type=int,\n",
        "                    default=150, help='maximum epoch number to train')\n",
        "parser.add_argument('--batch_size', type=int,\n",
        "                    default=24, help='batch_size per gpu')\n",
        "parser.add_argument('--n_gpu', type=int, default=1, help='total gpu')\n",
        "parser.add_argument('--deterministic', type=int,  default=1,\n",
        "                    help='whether use deterministic training')\n",
        "parser.add_argument('--base_lr', type=float,  default=0.01,\n",
        "                    help='segmentation network learning rate')\n",
        "parser.add_argument('--img_size', type=int,\n",
        "                    default=224, help='input patch size of network input')\n",
        "parser.add_argument('--seed', type=int,\n",
        "                    default=1234, help='random seed')\n",
        "parser.add_argument('--cfg', type=str, required=True, metavar=\"FILE\", help='path to config file', )\n",
        "parser.add_argument(\n",
        "        \"--opts\",\n",
        "        help=\"Modify config options by adding 'KEY VALUE' pairs. \",\n",
        "        default=None,\n",
        "        nargs='+',\n",
        "    )\n",
        "parser.add_argument('--zip', action='store_true', help='use zipped dataset instead of folder dataset')\n",
        "parser.add_argument('--cache-mode', type=str, default='part', choices=['no', 'full', 'part'],\n",
        "                    help='no: no cache, '\n",
        "                            'full: cache all data, '\n",
        "                            'part: sharding the dataset into nonoverlapping pieces and only cache one piece')\n",
        "parser.add_argument('--resume', help='resume from checkpoint')\n",
        "parser.add_argument('--accumulation-steps', type=int, help=\"gradient accumulation steps\")\n",
        "parser.add_argument('--use-checkpoint', action='store_true',\n",
        "                    help=\"whether to use gradient checkpointing to save memory\")\n",
        "parser.add_argument('--amp-opt-level', type=str, default='O1', choices=['O0', 'O1', 'O2'],\n",
        "                    help='mixed precision opt level, if O0, no amp is used')\n",
        "parser.add_argument('--tag', help='tag of experiment')\n",
        "parser.add_argument('--eval', action='store_true', help='Perform evaluation only')\n",
        "parser.add_argument('--throughput', action='store_true', help='Test throughput only')\n",
        "\n",
        "args = parser.parse_args()\n",
        "config = get_config(args)\n",
        "\n",
        "device = \"cuda\"\n",
        "\n",
        "model = SwinUnet(config, img_size=args.img_size, num_classes=args.num_classes).to(device)\n",
        "\n",
        "\n",
        "base_lr = args.base_lr\n",
        "num_classes = args.num_classes\n",
        "batch_size = args.batch_size * args.n_gpu\n",
        "# max_iterations = args.max_iterations\n",
        "db_train = CustomDataset(base_dir=args.root_path,\n",
        "                               transform=transforms.Compose(\n",
        "                                   [transforms.Resize(args.img_size), transforms.CenterCrop(args.img_size), transforms.ToTensor()]))\n",
        "print(\"The length of train set is: {}\".format(len(db_train)))\n",
        "\n",
        "def worker_init_fn(worker_id):\n",
        "    random.seed(args.seed + worker_id)\n",
        "\n",
        "\n",
        "trainloader = DataLoader(db_train, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True,\n",
        "                             worker_init_fn=worker_init_fn)\n",
        "if args.n_gpu > 1:\n",
        "    model = nn.DataParallel(model)\n",
        "model.train()\n",
        "\n",
        "\n",
        "snapshot_path = \"/content/snap\"\n",
        "# optimizer = optim.SGD(model.parameters(), lr=base_lr, momentum=0.9, weight_decay=0.0001)\n",
        "optimizer = optim.Adam(model.parameters(), lr=base_lr)\n",
        "writer = SummaryWriter(snapshot_path + '/log')\n",
        "iter_num = 0\n",
        "max_epoch = args.max_epochs\n",
        "max_iterations = args.max_epochs * len(trainloader)  # max_epoch = max_iterations // len(trainloader) + 1\n",
        "logging.info(\"{} iterations per epoch. {} max iterations \".format(len(trainloader), max_iterations))\n",
        "best_performance = 0.0\n",
        "iterator = tqdm(range(max_epoch), ncols=70)\n",
        "for epoch_num in iterator:\n",
        "    for i_batch, sampled_batch in enumerate(trainloader):\n",
        "        image_batch, label_batch = sampled_batch['image'], sampled_batch['label']\n",
        "        image_batch, label_batch = image_batch.to(device), label_batch.to(device)\n",
        "        outputs = model(image_batch)\n",
        "        loss = F.mse_loss(outputs, label_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_ = base_lr * (1.0 - iter_num / max_iterations) ** 0.9\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr_\n",
        "\n",
        "        iter_num = iter_num + 1\n",
        "        writer.add_scalar('info/lr', lr_, iter_num)\n",
        "        writer.add_scalar('info/total_loss', loss, iter_num)\n",
        "\n",
        "        logging.info('iteration %d : loss : %f' % (iter_num, loss.item()))\n",
        "        print('iteration %d : loss : %f' % (iter_num, loss.item()))\n",
        "\n",
        "    save_interval = 50  # int(max_epoch/6)\n",
        "    if epoch_num > int(max_epoch / 2) and (epoch_num + 1) % save_interval == 0:\n",
        "        save_mode_path = os.path.join(snapshot_path, 'epoch_' + str(epoch_num) + '.pth')\n",
        "        torch.save(model.state_dict(), save_mode_path)\n",
        "        logging.info(\"save model to {}\".format(save_mode_path))\n",
        "\n",
        "    if epoch_num >= max_epoch - 1:\n",
        "        save_mode_path = os.path.join(snapshot_path, 'epoch_' + str(epoch_num) + '.pth')\n",
        "        torch.save(model.state_dict(), save_mode_path)\n",
        "        logging.info(\"save model to {}\".format(save_mode_path))\n",
        "        iterator.close()\n",
        "        break\n",
        "\n",
        "writer.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LcAngl_3tDB",
        "outputId": "01881264-c3c9-4322-91bd-21e09413feff"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/Swin-Unet/train_custom.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Swin-Unet\n",
        "# 224の倍数ならいける\n",
        "# SwinTransformerSysのimg_sizeを調整できるようにすればいけそう\n",
        "!python train_custom.py --root_path /content/datasets --num_classes 3 --img_size 448 --batch_size 1 --cfg /content/Swin-Unet/configs/swin_tiny_patch4_window7_224_lite.yaml"
      ],
      "metadata": {
        "id": "Z5a9tPnI9CBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inference\n",
        "%%writefile /content/Swin-Unet/inference.py\n",
        "\n",
        "import argparse\n",
        "from networks.vision_transformer import SwinUnet\n",
        "from config import get_config\n",
        "import torch\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--root_path\", type=str, default=\"/content/datasets\")\n",
        "parser.add_argument('--num_classes', type=int,\n",
        "                    default=9, help='output channel of network')\n",
        "parser.add_argument('--output_dir', type=str, help='output dir')\n",
        "parser.add_argument('--max_iterations', type=int,\n",
        "                    default=30000, help='maximum epoch number to train')\n",
        "parser.add_argument('--max_epochs', type=int,\n",
        "                    default=150, help='maximum epoch number to train')\n",
        "parser.add_argument('--batch_size', type=int,\n",
        "                    default=24, help='batch_size per gpu')\n",
        "parser.add_argument('--n_gpu', type=int, default=1, help='total gpu')\n",
        "parser.add_argument('--deterministic', type=int,  default=1,\n",
        "                    help='whether use deterministic training')\n",
        "parser.add_argument('--base_lr', type=float,  default=0.01,\n",
        "                    help='segmentation network learning rate')\n",
        "parser.add_argument('--img_size', type=int,\n",
        "                    default=224, help='input patch size of network input')\n",
        "parser.add_argument('--seed', type=int,\n",
        "                    default=1234, help='random seed')\n",
        "parser.add_argument('--cfg', type=str, required=True, metavar=\"FILE\", help='path to config file', )\n",
        "parser.add_argument(\n",
        "        \"--opts\",\n",
        "        help=\"Modify config options by adding 'KEY VALUE' pairs. \",\n",
        "        default=None,\n",
        "        nargs='+',\n",
        "    )\n",
        "parser.add_argument('--zip', action='store_true', help='use zipped dataset instead of folder dataset')\n",
        "parser.add_argument('--cache-mode', type=str, default='part', choices=['no', 'full', 'part'],\n",
        "                    help='no: no cache, '\n",
        "                            'full: cache all data, '\n",
        "                            'part: sharding the dataset into nonoverlapping pieces and only cache one piece')\n",
        "parser.add_argument('--resume', help='resume from checkpoint')\n",
        "parser.add_argument('--accumulation-steps', type=int, help=\"gradient accumulation steps\")\n",
        "parser.add_argument('--use-checkpoint', action='store_true',\n",
        "                    help=\"whether to use gradient checkpointing to save memory\")\n",
        "parser.add_argument('--amp-opt-level', type=str, default='O1', choices=['O0', 'O1', 'O2'],\n",
        "                    help='mixed precision opt level, if O0, no amp is used')\n",
        "parser.add_argument('--tag', help='tag of experiment')\n",
        "parser.add_argument('--eval', action='store_true', help='Perform evaluation only')\n",
        "parser.add_argument('--throughput', action='store_true', help='Test throughput only')\n",
        "\n",
        "args = parser.parse_args()\n",
        "config = get_config(args)\n",
        "\n",
        "device = \"cuda\"\n",
        "model = SwinUnet(config, img_size=args.img_size, num_classes=args.num_classes).to(device)\n",
        "model.load_state_dict(torch.load(\"/content/snap/epoch_149.pth\"))\n",
        "model.eval()\n",
        "\n",
        "# transformしてtensorに直して画像を出力って感じか\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXjXEXXKB2Wm",
        "outputId": "f1fd23a6-0916-4809-b1d2-d6e70059a011"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/Swin-Unet/inference.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Swin-Unet/\n",
        "!python inference.py --img_size 448 --num_classes 3 --batch_size 1 --cfg /content/Swin-Unet/configs/swin_tiny_patch4_window7_224_lite.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2gBrjLlClwE",
        "outputId": "5d33471e-e560-4229-c78d-310047d7bc6b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Swin-Unet\n",
            "=> merge config from /content/Swin-Unet/configs/swin_tiny_patch4_window7_224_lite.yaml\n",
            "SwinTransformerSys expand initial----depths:[2, 2, 2, 2];depths_decoder:[1, 2, 2, 2];drop_path_rate:0.2;num_classes:3\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3609.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "---final upsample expand_first---\n",
            "/content/Swin-Unet/inference.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"/content/snap/epoch_149.pth\"))\n"
          ]
        }
      ]
    }
  ]
}